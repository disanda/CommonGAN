# 验证单数据集下，网络规模，LS（z_dim）维度，loss 不同情况下的效果

python train_mnist.py --experiment_name=mnist64 
# 如果 z_dim=64,   DG=512， 网络很快会训练到全黑模式
#      z_dim=64,  DG=1024, 即网络规模扩大一倍，效果得到好转, 但还是黑


python train_mnist.py --experiment_name=mnist64 --z_dim=128
# 抹去了网络中的均值，z_dim维度和GD参数同时扩大 [128,2048] , 效果大幅提升

python train_mnist.py --experiment_name=mnist64_zDim128 --z_dim=128 --Gscale=16
# 解除z_dim和GD参数同步, 同时在小规模GD下训练[128,1024],不太稳定，最终崩溃，换一个loss试一下。

python train_mnist.py --experiment_name=mnist64_zDim128_hingev1 --z_dim=128 --Gscale=8 --adversarial_loss_mode=hinge_v1
# 效果大幅提升SVM的多维分类性能显著提高性能，配合LS对称

python train_mnist.py --experiment_name=mnist64_zDim128_hingev1 --z_dim=128 --Gscale=4 --adversarial_loss_mode=hinge_v1
# 

# 验证一个生成器生成多个数据集

python train_multi_mnist.py --experiment_name=nd64_zDim128_hingev1 --z_dim=128 --Gscale=4 --adversarial_loss_mode=hinge_v1
# Mnist+FashionMnist

python train_multi_dataSet.py --experiment_name=nd64_zDim128_hingev1_Mni_Fashion_3dFace --z_dim=128 --Gscale=4 --adversarial_loss_mode=hinge_v1

